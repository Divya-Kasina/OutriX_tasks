
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from wordcloud import WordCloud
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.multiclass import OneVsRestClassifier


nltk.download('stopwords')
stop_words = set(stopwords.words('english'))


df = pd.read_csv("/content/amazon Reviews.csv")
df = df.dropna(subset=['Summary', 'Text'])

# Assign Sentiment Labels: Negative=-1, Neutral=0, Positive=1
def map_sentiment(score):
    if score < 3:
        return -1
    elif score == 3:
        return 0
    else:
        return 1
df['sentiment'] = df['Score'].apply(map_sentiment)

def clean_text(text):
    return "".join([c for c in str(text) if c not in ('?', '.', ';', ':', '!', '"')])
df['Text'] = df['Text'].apply(clean_text)
df['Summary'] = df['Summary'].apply(clean_text)
df['combined'] = df['Summary'] + " " + df['Text']

for label, label_name in [(-1, "Negative"), (0, "Neutral"), (1, "Positive")]:
    reviews = " ".join(df[df['sentiment'] == label]['combined'])
    wordcloud = WordCloud(width=800, height=400, background_color='white',
                          colormap='Reds' if label == -1 else 'Blues' if label == 0 else 'Greens',
                          stopwords=stop_words).generate(reviews)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Word Cloud - {label_name} Sentiment")
    plt.show()
 
train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['sentiment'])

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X_train = vectorizer.fit_transform(train['combined'])
X_test = vectorizer.transform(test['combined'])
y_train = train['sentiment']
y_test = test['sentiment']

scaler = StandardScaler(with_mean=False)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = {
    "Logistic Regression": LogisticRegression(max_iter=6000),
    "Naive Bayes": MultinomialNB(),
    "Decision Tree": DecisionTreeClassifier(max_depth=10, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5)
}

classes = [-1, 0, 1]
y_test_bin = label_binarize(y_test, classes=classes)
auc_scores = {}

plt.figure(figsize=(10, 6))
for name, model in models.items():
    print(f"\n{name} Training and Evaluation")
    clf = OneVsRestClassifier(model)
    clf.fit(X_train, y_train)
    preds = clf.predict(X_test)
    print(classification_report(y_test, preds))
    print("Confusion Matrix:\n", confusion_matrix(y_test, preds))

    if hasattr(clf, "predict_proba"):
        y_score = clf.predict_proba(X_test)
    else:
        y_score = clf.decision_function(X_test)

    # ROC Curve for each class
    for i, cls in enumerate(classes):
        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"{name} (Class {cls}, AUC={roc_auc:.2f})")
        auc_scores[f"{name} (Class {cls})"] = roc_auc

# Plot ROC
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Multi-Class ROC Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()

# AUC Bar Chart
plt.figure(figsize=(10, 4))
plt.barh(list(auc_scores.keys()), list(auc_scores.values()), color='lightseagreen')
plt.title("Model AUC Scores by Class")
plt.xlabel("AUC")
plt.tight_layout()
plt.show()
